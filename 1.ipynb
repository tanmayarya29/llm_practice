{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers pandas scipy numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, AutoTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b600c3a4a4894ce68e334d7a0e49396e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a07d6f73c4442280db923388bbbef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b985cf55c714d62929e027caff2510e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e6522730b142b8bcc06607ac412833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544da91bc2d24a6cb40f870c1dd272df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"When life gives you lemons,don't make lemonade.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When',\n",
       " 'life',\n",
       " 'gives',\n",
       " 'you',\n",
       " 'lemon',\n",
       " '##s',\n",
       " ',',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'make',\n",
       " 'lemon',\n",
       " '##ade',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PAD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[unused1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[unused2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[unused3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[unused4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28991</th>\n",
       "      <td>##）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28992</th>\n",
       "      <td>##，</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28993</th>\n",
       "      <td>##－</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28994</th>\n",
       "      <td>##／</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28995</th>\n",
       "      <td>##：</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28996 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              token\n",
       "token_id           \n",
       "0             [PAD]\n",
       "1         [unused1]\n",
       "2         [unused2]\n",
       "3         [unused3]\n",
       "4         [unused4]\n",
       "...             ...\n",
       "28991           ##）\n",
       "28992           ##，\n",
       "28993           ##－\n",
       "28994           ##／\n",
       "28995           ##：\n",
       "\n",
       "[28996 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.vocab\n",
    "vocab_df = pd.DataFrame({\"token\":vocab.keys(),\"token_id\":vocab.values()})\n",
    "vocab_df = vocab_df.sort_values(by=\"token_id\").set_index(\"token_id\")\n",
    "vocab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 1332,\n",
       " 1297,\n",
       " 3114,\n",
       " 1128,\n",
       " 22782,\n",
       " 1116,\n",
       " 117,\n",
       " 1274,\n",
       " 112,\n",
       " 189,\n",
       " 1294,\n",
       " 22782,\n",
       " 6397,\n",
       " 119,\n",
       " 102]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = tokenizer.encode(sentence)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 - 16\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens),\"-\",len(token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token    [CLS]\n",
       "Name: 101, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_df.iloc[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token    [SEP]\n",
       "Name: 102, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_df.iloc[102]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('When', 1332),\n",
       " ('life', 1297),\n",
       " ('gives', 3114),\n",
       " ('you', 1128),\n",
       " ('lemon', 22782),\n",
       " ('##s', 1116),\n",
       " (',', 117),\n",
       " ('don', 1274),\n",
       " (\"'\", 112),\n",
       " ('t', 189),\n",
       " ('make', 1294),\n",
       " ('lemon', 22782),\n",
       " ('##ade', 6397),\n",
       " ('.', 119)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(tokens, token_ids[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"When life gives you lemons, don't make lemonade.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(token_ids[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1332, 1297, 3114, 1128, 22782, 1116, 117, 1274, 112, 189, 1294, 22782, 6397, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_out = tokenizer(sentence)\n",
    "tokenizer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = sentence.replace(\"don't\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1332, 1297, 3114, 1128, 22782, 1116, 117, 1274, 112, 189, 1294, 22782, 6397, 119, 102], [101, 1332, 1297, 3114, 1128, 22782, 1116, 117, 1294, 22782, 6397, 119, 102, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_out2 = tokenizer([sentence,sentence2],padding = True)\n",
    "# padding = True will add padding tokens to make the input the same length. used when no of sentences are even\n",
    "tokenizer_out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] When life gives you lemons, don't make lemonade. [SEP]\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer_out2[\"input_ids\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] When life gives you lemons, make lemonade. [SEP] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer_out2[\"input_ids\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Tokenize me this please\"\n",
    "encoded_inputs = tokenizer(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 6.3545e-01,  1.7615e-01,  6.1589e-01,  ..., -1.1664e-01,\n",
       "           5.5535e-01, -2.4577e-01],\n",
       "         [ 2.6871e-01,  1.0804e-01, -7.9291e-02,  ...,  8.8400e-02,\n",
       "           8.2027e-01, -7.8417e-04],\n",
       "         [ 5.9982e-02,  5.7306e-01, -2.6445e-01,  ...,  2.0249e-01,\n",
       "          -8.9708e-01,  2.3878e-01],\n",
       "         ...,\n",
       "         [-1.6705e-01,  3.0571e-01,  4.3537e-01,  ...,  8.0311e-02,\n",
       "           2.3093e-01,  1.8002e-01],\n",
       "         [ 4.5541e-01,  1.2220e-01,  5.8000e-01,  ...,  3.0526e-01,\n",
       "           5.1684e-01, -2.6089e-01],\n",
       "         [ 7.1148e-01,  3.9665e-02,  3.6133e-01,  ..., -4.8748e-01,\n",
       "           5.2402e-01, -8.0548e-01]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.7571,  0.5197,  0.9999, -0.9967,  0.9707,  0.9701,  0.9926, -0.9949,\n",
       "         -0.9859, -0.6731,  0.9896,  0.9993, -0.9988, -0.9999,  0.8604, -0.9850,\n",
       "          0.9931, -0.5585, -1.0000, -0.5781, -0.6435, -0.9999,  0.1552,  0.9768,\n",
       "          0.9878,  0.1029,  0.9929,  1.0000,  0.8974, -0.2188,  0.2532, -0.9955,\n",
       "          0.8232, -0.9994,  0.1654,  0.1601,  0.6032, -0.2848,  0.7803, -0.9705,\n",
       "         -0.7546, -0.4581,  0.6860, -0.5660,  0.9705,  0.2324,  0.0123,  0.0351,\n",
       "          0.0350,  0.9999, -0.9770,  0.9985, -0.9960,  0.9980,  0.9982,  0.4647,\n",
       "          0.9974,  0.1615, -0.9992,  0.3755,  0.9722,  0.2300,  0.9536, -0.2489,\n",
       "          0.3661, -0.5718, -0.8706,  0.1662, -0.5311,  0.3377,  0.3172,  0.3148,\n",
       "          0.9917, -0.9334, -0.0862, -0.9375,  0.0015, -0.9999,  0.9716,  1.0000,\n",
       "          0.7328, -0.9998,  0.9978, -0.2295, -0.7797,  0.6083, -0.9990, -0.9997,\n",
       "          0.1160, -0.6008,  0.9560, -0.9938,  0.7354, -0.9208,  1.0000, -0.9690,\n",
       "         -0.1394,  0.4528,  0.9750, -0.7369, -0.8027,  0.9532,  0.9992, -0.9949,\n",
       "          0.9989,  0.7893, -0.9579, -0.9086,  0.7907,  0.1189,  0.9945, -0.9915,\n",
       "         -0.9258,  0.0540,  0.9790, -0.9037,  0.9951,  0.6319, -0.3201,  1.0000,\n",
       "         -0.2164,  0.9681,  0.9993,  0.8552, -0.8630, -0.1896, -0.6129,  0.9199,\n",
       "         -0.5439, -0.5080,  0.7987, -0.9956, -0.9986,  0.9998, -0.2904,  1.0000,\n",
       "         -0.9996,  0.9966, -1.0000, -0.8288, -0.8360, -0.0029, -0.9900,  0.1884,\n",
       "          0.9947,  0.0765, -0.9738, -0.8921,  0.5486, -0.8889,  0.6414,  0.7967,\n",
       "         -0.9837,  0.9955,  0.9978,  0.9709,  0.9908,  0.1770, -0.9699,  0.9345,\n",
       "          0.9930, -0.9998,  0.7275, -0.9964,  0.9996,  0.9818,  0.7734, -0.9964,\n",
       "          0.9999, -0.6898, -0.0486, -0.2404, -0.0845, -0.9992,  0.5061,  0.3866,\n",
       "          0.8177,  0.9997, -0.9976,  0.9996,  0.9540,  0.0023,  0.8341,  0.9991,\n",
       "         -0.9982, -0.9891, -0.9931,  0.2792,  0.7637,  0.6106,  0.3757,  0.9725,\n",
       "          0.9989,  0.7837, -0.9987, -0.3490,  0.9887, -0.2241,  1.0000, -0.4741,\n",
       "         -0.9999, -0.7258,  0.9569,  0.9916, -0.3072,  0.9892, -0.7812, -0.1176,\n",
       "          0.9900, -0.9951,  0.9982,  0.3805,  0.9100,  0.9016,  0.9971, -0.8809,\n",
       "         -0.1179,  0.2488, -0.7342,  0.9999, -0.9998, -0.1622,  0.5727, -0.9965,\n",
       "         -0.9991,  0.9923,  0.0035, -0.8535, -0.2706,  0.7472,  0.3042,  0.9468,\n",
       "          0.9956, -0.6432, -0.6999, -0.9999, -0.9972, -0.8861, -0.9700,  0.1222,\n",
       "          0.6960, -0.3968, -0.9467, -0.9987,  0.9813,  0.8097, -0.9506, -0.2361,\n",
       "         -0.6971, -0.9987,  0.3860, -0.8952, -0.9989,  0.9998, -0.8629,  0.9972,\n",
       "          0.9824, -0.9974,  0.8285, -0.9990, -0.0276, -0.9979,  0.3454,  0.6966,\n",
       "         -0.7146,  0.0356,  0.9966, -0.9814, -0.8772,  0.8763, -1.0000,  0.9599,\n",
       "         -0.2212,  0.9996,  0.7945, -0.0016,  0.9911,  0.9540, -0.9910, -0.9999,\n",
       "          0.9584,  0.9716, -0.9968, -0.2010,  1.0000, -0.9982, -0.8484, -0.9731,\n",
       "         -0.9978, -0.9998,  0.2274, -0.7957,  0.1766,  0.9910,  0.3693,  0.1538,\n",
       "          0.9971,  0.9969,  0.1848, -0.2017,  0.0316, -0.9887, -0.9849,  0.8403,\n",
       "          0.2262, -1.0000,  0.9999, -0.9975,  0.9977,  0.9588, -0.9961,  0.8365,\n",
       "          0.0820, -0.9739,  0.0583,  0.9999,  0.9920, -0.0178,  0.1314,  0.9258,\n",
       "         -0.3291,  0.6373, -0.8069, -0.7123,  0.1816, -0.9515,  0.9944,  0.8435,\n",
       "         -0.9962,  0.9971,  0.0223,  0.8430, -0.8664,  0.9275,  0.9962, -0.1306,\n",
       "         -0.5234, -0.0942, -0.5088, -0.9850,  0.1606, -0.9973, -0.5116,  0.8939,\n",
       "          0.9950, -0.9945,  0.9961, -0.2122,  0.9520, -0.9981,  1.0000, -0.9990,\n",
       "          0.1373,  0.7074, -0.8190, -0.7289,  0.9963,  0.9873,  0.9868, -0.9696,\n",
       "         -0.7980,  0.8918,  0.9827, -0.9810,  0.0216, -0.9994, -0.8124,  0.9980,\n",
       "          0.9970, -0.0297, -0.3829, -0.9980,  0.9733, -0.8571, -0.9477, -0.1020,\n",
       "         -0.9060,  0.8072,  0.9983, -0.7311,  0.7485,  0.0850, -0.9948,  0.9285,\n",
       "          0.7695,  0.9999, -0.9878,  0.4792,  0.9946, -0.2842, -0.7827,  0.6173,\n",
       "          0.9994, -0.9810, -0.2885, -0.9998,  0.0882, -0.7892, -0.0856, -0.2855,\n",
       "          0.1612, -0.8750,  0.9784,  0.0583,  0.8608, -0.2981,  0.9860,  0.0941,\n",
       "         -0.0199, -0.3592, -0.3529,  0.5728,  0.1778,  0.9927, -0.9869,  0.9998,\n",
       "         -0.3991, -1.0000, -0.9974, -0.8540, -0.9997,  0.7324, -0.9974,  0.9942,\n",
       "          0.9693, -0.9984, -0.9994, -0.9992, -0.9973,  0.8477,  0.7326, -0.0584,\n",
       "          0.3667,  0.3359,  0.0792, -0.0218, -0.0274, -0.9620, -0.5167, -0.9985,\n",
       "          0.7891, -1.0000, -0.8156,  0.9981, -0.9967, -0.8957, -0.9610, -0.9234,\n",
       "         -0.8407,  0.6460,  0.9922, -0.3712, -0.6447, -0.9997,  0.9939, -0.7828,\n",
       "          0.1627, -0.8981, -0.9862,  0.9998,  0.9534, -0.1952, -0.1010, -0.9994,\n",
       "          0.9908, -0.9236, -0.9433, -0.9916,  0.2077, -0.9675, -0.9999, -0.0030,\n",
       "          0.9971,  0.9978,  0.9860,  0.2784, -0.4012, -0.9569,  0.2485, -1.0000,\n",
       "          0.8845,  0.8966, -0.9927, -0.7827,  0.9960,  0.9894, -0.9623, -0.9864,\n",
       "          0.9782,  0.3764,  0.9776, -0.6116, -0.5734,  0.3542, -0.0645, -0.9943,\n",
       "         -0.9721,  0.9984, -0.9993,  0.9866,  0.9976,  0.9991, -0.1521,  0.1320,\n",
       "         -0.9898, -0.9955, -0.6499,  0.3694, -1.0000,  0.9999, -1.0000,  0.5491,\n",
       "         -0.8240,  0.9129,  0.9945, -0.4654, -1.0000, -0.9999,  0.3485,  0.0081,\n",
       "          0.9960,  0.2759,  0.3342, -0.6858,  0.2105,  0.9990, -0.6438, -0.8236,\n",
       "         -0.9985,  0.9998,  0.6440, -0.9995,  0.9965, -0.9997,  0.9056,  0.9894,\n",
       "          0.9542,  0.9882, -0.9992,  1.0000, -0.9999,  0.9983, -1.0000, -0.9992,\n",
       "          0.9999, -0.9956, -0.8023, -0.9999, -0.9985,  0.6966,  0.1030, -0.5456,\n",
       "          0.9961, -0.9999, -0.9994, -0.3406, -0.9333, -0.8226,  0.9959, -0.6732,\n",
       "          0.9964, -0.1598,  0.9662,  0.3991,  0.9980,  0.9984, -0.8217, -0.8651,\n",
       "         -0.9963,  0.9909, -0.6722,  0.4460,  0.9823, -0.0578, -0.8412,  0.4005,\n",
       "         -0.9987,  0.5920, -0.4776,  0.9351,  0.9175,  0.8852, -0.0546, -0.5004,\n",
       "         -0.2392, -0.9975,  0.6273, -0.9998,  0.9916, -0.9578,  0.1025, -0.4840,\n",
       "          0.4481, -0.9555,  0.9998,  0.9993, -0.9986,  0.1025,  0.9945, -0.8007,\n",
       "          0.9881, -0.9963,  0.1006,  0.9767, -0.7371,  0.9916,  0.1164, -0.1511,\n",
       "          0.9901, -0.9979, -0.9276, -0.7437,  0.4054,  0.2443, -0.9837,  0.1230,\n",
       "          0.9890, -0.3768, -0.9999,  0.9695, -0.9997, -0.1793,  0.9889,  0.1082,\n",
       "          1.0000, -0.8352,  0.1009,  0.1437, -0.9999, -0.9993,  0.1010, -0.1563,\n",
       "         -0.9297,  0.9993, -0.2370,  0.8603, -0.9999,  0.3307,  0.9970,  0.3393,\n",
       "          0.9028, -0.8580, -0.9738, -0.9762, -0.6804,  0.0464,  0.9261, -0.9905,\n",
       "         -0.8090, -0.8957,  1.0000, -0.9991, -0.9553, -0.9953,  0.4388,  0.9319,\n",
       "          0.4935,  0.0182, -0.9344,  0.9432, -0.9575,  0.9983, -0.9981, -0.9985,\n",
       "          0.9999,  0.4540, -0.9958,  0.3697, -0.3319,  0.4963,  0.0590,  0.8047,\n",
       "         -0.9039, -0.2252, -0.9987,  0.5132, -0.8915, -0.9951, -0.6478, -0.3970,\n",
       "         -0.9967,  0.9975,  0.9855,  1.0000, -0.9999,  0.8953,  0.0767,  0.9995,\n",
       "          0.0456, -0.7227,  0.9297,  0.9998, -0.7987,  0.8162, -0.0540, -0.0699,\n",
       "          0.3983, -0.5634,  0.9978, -0.9397,  0.3580, -0.9913, -1.0000,  1.0000,\n",
       "         -0.0789,  0.9941,  0.2283,  0.8258, -0.9260,  0.9846, -0.9897, -0.9264,\n",
       "         -1.0000,  0.2482, -0.9988, -0.9952,  0.0202,  0.9952, -0.9998, -0.9957,\n",
       "         -0.2742, -1.0000,  0.9035, -0.9914, -0.8678, -0.9947,  0.9978, -0.3438,\n",
       "         -0.7682,  0.9893, -0.9866,  0.9619,  0.9178,  0.0304,  0.2780,  0.1900,\n",
       "         -0.7325, -0.9961, -0.9547, -0.9828,  0.7925, -0.9946, -0.9150,  0.9984,\n",
       "          0.9940, -0.9996, -0.9983,  0.9970,  0.1111,  0.9962, -0.6271, -0.9999,\n",
       "         -1.0000,  0.1750, -0.0738,  0.9981, -0.4339,  0.9905,  0.8078, -0.5150,\n",
       "          0.6823, -0.6820, -0.3612, -0.4140, -0.2183,  1.0000, -0.8331,  0.9958]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(**encoded_inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_state = output.last_hidden_state\n",
    "pooler_output = output.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    encoded_inputs = tokenizer(text, return_tensors='pt')\n",
    "    return model(**encoded_inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"There was a fly drinking from the soup\"\n",
    "sentence2 = \"To become a commercial pilot, he had to fly for 1500 hours\"\n",
    "\n",
    "tokens1 = tokenizer.tokenize(sentence1)\n",
    "tokens2 = tokenizer.tokenize(sentence2)\n",
    "\n",
    "out1 = predict(sentence1)\n",
    "out2 = predict(sentence2) \n",
    "\n",
    "emb1 = out1[0:,tokens1.index(\"fly\"),:].detach()\n",
    "emb2 = out1[0:,tokens2.index(\"fly\"),:].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb1.shape, emb2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7663925588130951"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(emb1.numpy().flatten(), emb2.numpy().flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from scipy.special import softmax\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = \"bert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to have pizza for tonight. - 0.257289\n",
      "I want to get pizza for tonight. - 0.17849614\n",
      "I want to eat pizza for tonight. - 0.15555531\n",
      "I want to make pizza for tonight. - 0.11422412\n",
      "I want to order pizza for tonight. - 0.09823137\n"
     ]
    }
   ],
   "source": [
    "mask = tokenizer.mask_token\n",
    "sentence = f\"I want to {mask} pizza for tonight.\"\n",
    "\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "encoded_inputs = tokenizer(sentence, return_tensors='pt')\n",
    "output = model(**encoded_inputs)\n",
    "logits = output.logits.detach().numpy()[0]\n",
    "\n",
    "mask_logits = logits[tokens.index(mask)+1]\n",
    "confidence_score = softmax(mask_logits)\n",
    "\n",
    "for i in np.argsort(confidence_score)[::-1][:5]:\n",
    "    pred_token = tokenizer.decode(i)\n",
    "    score = confidence_score[i]\n",
    "    \n",
    "    # print(f\"{pred_token} - {score:.2f}\")\n",
    "    print(sentence.replace(mask,pred_token),\"-\",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (2.17.0)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from datasets) (3.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from datasets) (1.24.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from sentence-transformers) (4.37.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from sentence-transformers) (1.10.1)\n",
      "Collecting nltk (from sentence-transformers)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece (from sentence-transformers)\n",
      "  Downloading sentencepiece-0.1.99-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from sentence-transformers) (9.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: sympy in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Collecting click (from nltk->sentence-transformers)\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Installing collected packages: sentencepiece, click, nltk, sentence-transformers\n",
      "Successfully installed click-8.1.7 nltk-3.8.1 sentence-transformers-2.3.1 sentencepiece-0.1.99\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5655dc4aabde48909cde36a748b7cfb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/295M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700f2a5060fd4719b0bcd885e984f8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/28.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a1d7d0c52a4d3c9c7b49e370fd7deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/39.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3214592bbb64473e9497f4034de49a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/40.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7117a1bdebd4550bc3078ab847d6d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/44972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c6cb8ca52746398ab1d7ec1eea7ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5622 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7bb8cf89b7449a849073bf70aa4e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5622 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"multi_news\", split=\"test\")\n",
    "df = dataset.to_pandas().sample(2000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d6677ab28c498198124dcf54d80e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce87a6e703843cda4b6466deff2bbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae6b69515a34e308ec6b12bbdedd9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4725d5d14e43ab8820e02dbe7e3ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d56e510bee4118a7fcf01cc7f06b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce4f24784044e6bbace9b0e0cdf0714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23f8355f124432cb5388dec5cd54bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920e08ebf42540028b803d0c011cd3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c402351599ea456583343a302c667093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b8f5c60d704eb7a0f2ca5c08d2abe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5819e48e67413f9eac1a3140682461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c34a37bc1a543d7bdee9bc29b8f4f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "passage_embeddings = list(model.encode(df[\"summary\"].to_list(),show_progress_bar=True))\n",
    "passage_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Find me some articles about technology and artificial intelligence\"\n",
    "query_embedding = model.encode(query)\n",
    "query_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tannmaymishra/miniforge3/envs/myenv/lib/python3.11/site-packages/sentence_transformers/util.py:40: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/miniforge3/conda-bld/pytorch-recipe_1680607563975/work/torch/csrc/utils/tensor_new.cpp:248.)\n",
      "  b = torch.tensor(b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2000])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = util.cos_sim(query_embedding, passage_embeddings)\n",
    "similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1266, 1834, 1612])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_indices = torch.topk(similarities.flatten(), 3).indices\n",
    "top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['– Are you a \"digital native\" or a \"digital immigrant,\" and does it make a difference? Research recently published in the Teaching and Teacher Education journal indicates the concept of so-called digit...',\n",
       " \"– Using methods borrowed from Google, a group of researchers has analyzed all Wikipedia pages and determined that, at least on the English language version of the site, Frank Sinatra is the world's mo...\",\n",
       " '– The \"tech surge\" to fix HealthCare.gov includes some names from the industry\\'s biggest players. Among them, per a Health department blog post, is Michael Dickerson, on leave from his job as a site r...']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_relevent_passages = [df.iloc[x.item()][\"summary\"][:200] +\"...\" for x in top_indices]\n",
    "top_relevent_passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relavant_news(query):\n",
    "    query_embedding = model.encode(query)\n",
    "    similarities = util.cos_sim(query_embedding, passage_embeddings)\n",
    "    top_indices = torch.topk(similarities.flatten(), 3).indices\n",
    "    top_relevent_passages = [df.iloc[x.item()]['summary'][:200] + \"...\" for x in top_indices]\n",
    "    \n",
    "    return top_relevent_passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['– Hopes are fading for people still believed to be trapped under mud and debris after a massive landslide in Washington state. At least eight people have now been confirmed dead from the mudslide that...',\n",
       " '– A sad milestone out of Japan: Two weeks after the quake struck, its official death toll has broken the 10,000 mark—and that number is still on the rise, with more than 17,400 missing. Police estimat...',\n",
       " '– A Haitian Red Cross official estimated today that 45,000 to 50,000 people perished in the shattering earthquake Tuesday, as President Obama pledged US support of $100 million for what he said is lik...']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_relavant_news(\"Natural disaster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
